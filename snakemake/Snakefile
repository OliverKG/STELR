import os
import subprocess

rule all:
    input: 
        "reads.contigs.fa",
        "intermediate_files/reads.vcf_filtered.tsv"
        #"{sample_name}.loci_eval.tsv"

def input_reads_if_in_bam_format(wildcards):
    #   this rule returns the bam format input if the input is given in bam format, or an empty list if not.
    #returning an empty list essentially gives snakemake permission to accept the input file in fasta 
    #format; otherwise it tries to check the next file back in the workflow, and causes a cyclic dependency
    #error if the input and output for the rule bam_input are the same.
    if ".bam" in config["reads"]: return config["reads"]
    else: return []
rule bam_input: #if input is given in bam format, convert it to fasta format.
    #todo -- check if this bam format is ACTUALLY aligned.
    input:
        input_reads_if_in_bam_format
    output:
        config["fasta_reads"]
    shell:
        "python3 TELR_alignment.py bam2fasta {input} {output}"

"""
1st stage: identify TE insertion candidate loci
"""

'''1st stage
"Read alignment (NGMLR)"
^(or minimap2)
'''
#only run if reads are supplied in fasta format
rule alignment:
    input:
        config["fasta_reads"]
    output:
        "intermediate_files/{sample_name}.sam"
    params:
        reads = config["fasta_reads"],
        reference = config["reference"],
        out = "intermediate_files",
        method = config["aligner"],#minimap2 or ngmlr
        presets = config["presets"]#ont or pacbio
    threads: config["thread"]
    shell:
        "python3 TELR_alignment.py alignment {params.reads} {params.reference} {params.out} {wildcards.sample_name} {threads} {params.method} {params.presets}"

def find_alignment(wildcards):
    bam_input = f"intermediate_files/input/reads-{wildcards.sample_name}.bam"
    if(os.path.isfile(bam_input)): return bam_input
    else: return f"intermediate_files/{wildcards.sample_name}.sam"
rule sort_index_bam:
    input:
        find_alignment#gives name of input file (this depends on whether the user supplied input was in bam format or it was aligned later)
    output:
        "intermediate_files/{sample_name}_sort.bam"
    threads: config["thread"]
        #samtools
    shell:
        "python3 TELR_alignment.py sort_index_bam {input} {output} {threads}"
    
'''1st stage
SV calling (Sniffles)
'''
rule detect_sv:
    input:
        bam = "intermediate_files/{sample_name}_sort.bam",
        reference = config["reference"]
    output:
        "intermediate_files/{sample_name}_{sv_detector}.vcf"
    params:
        out = "intermediate_files",
        sample_name = config["sample_name"],
        thread = config["thread"]
    shell:
        "python3 TELR_sv.py detect_sv {input.bam} {input.reference} {params.out} {params.sample_name} {params.thread}"

rule parse_vcf:
    input:
        "intermediate_files/{sample_name}_Sniffles.vcf"#replace Sniffles with config[sv_detector] later if there are options
    output:
        "intermediate_files/{sample_name}.vcf_parsed.tsv.tmp"
    params:
        '"%CHROM\\t%POS\\t%END\\t%SVLEN\\t%RE\\t%AF\\t%ID\\t%ALT\\t%RNAMES\\t%FILTER\\t[ %GT]\\t[ %DR]\\t[ %DV]\n"'
        #bcftools
    shell:
        'bcftools query -i \'SVTYPE="INS" & ALT!="<INS>"\' -f {params} {input} > {output}'

rule swap_vcf_coordinate:
    input:
        "intermediate_files/{sample_name}.vcf_parsed.tsv.tmp"
    output:
        "intermediate_files/{sample_name}.vcf_parsed.tsv.swap"
    shell:
        "python3 TELR_sv.py swap_coordinate {input} {output}"

rule rm_vcf_redundancy:
    input:
        "intermediate_files/{sample_name}.vcf_parsed.tsv.swap"
    output:
        "intermediate_files/{sample_name}.vcf_parsed.tsv"
    shell:
        "python3 TELR_sv.py rm_vcf_redundancy {input} {output}"

rule write_ins_seqs:
    input:
        "intermediate_files/{sample_name}.vcf_parsed.tsv"
    output:
        "intermediate_files/{sample_name_plus}.vcf_ins.fasta"
    shell:
        "python3 TELR_sv.py write_ins_seqs {input} {output}"

'''1st stage
Filter for TE insertion candidate (RepeatMasker)
'''

rule sv_repeatmask:
    input:
        ins_seqs = lambda wildcards: f"intermediate_files/{config['sample_name'].replace('+','plus')}.vcf_ins.fasta",
        library = config["library"]
    output:
        "intermediate_files/vcf_ins_repeatmask/{ins_seqs}.out.gff"
    params:
        repeatmasker_dir = "intermediate_files/vcf_ins_repeatmask",
        thread = config["thread"]
    shell:
        "python3 TELR_sv.py repeatmask {params.repeatmasker_dir} {input.ins_seqs} {input.library} {params.thread}"

rule sv_RM_sort:
    input:
        "intermediate_files/vcf_ins_repeatmask/{ins_seqs}.out.gff"
    output:
        "intermediate_files/vcf_ins_repeatmask/{ins_seqs}.out.sort.gff"
        #bedtools
    shell:
        "bedtools sort -i {input} > {output}"

rule sv_RM_merge:
    input:
        "intermediate_files/vcf_ins_repeatmask/{ins_seqs}.out.sort.gff"
    output:
        "intermediate_files/vcf_ins_repeatmask/{ins_seqs}.out.merge.bed"
        #bedtools
    shell:
        "bedtools merge -i {input} > {output}"

rule sv_TE_extract:
    input:
        parsed_vcf = "intermediate_files/{sample_name}.vcf_parsed.tsv",
        ins_seqs = lambda wildcards: f"intermediate_files/{config['sample_name'].replace('+','plus')}.vcf_ins.fasta",
        ins_rm_merge = lambda wildcards: f"intermediate_files/vcf_ins_repeatmask/{config['sample_name'].replace('+','plus')}.vcf_ins.fasta.out.merge.bed"
    output:
        ins_filtered = "intermediate_files/{sample_name}.vcf.filtered.tmp.tsv",
        loci_eval = "{sample_name}.loci_eval.tsv"
    shell:
        "python3 TELR_sv.py te_extract {input.parsed_vcf} {input.ins_seqs} {input.ins_rm_merge} {output.ins_filtered} {output.loci_eval}"

rule seq_merge:
    input:
        "intermediate_files/{sample_name}.vcf.filtered.tmp.tsv"
    output: 
        "intermediate_files/{sample_name}.vcf.merged.tmp.tsv"
    params:
        window = 20
        #bedtools
    shell:
        'bedtools merge -o collapse -c 2,3,4,5,6,7,8,9,10,11,12,13,14 -delim ";" -d {params.window} -i {input} > {output}'

checkpoint merge_parsed_vcf:
    input:
        "intermediate_files/{sample_name}.vcf.merged.tmp.tsv"
    output:
        "intermediate_files/{sample_name}.vcf_filtered.tsv"
    shell:
        "python3 TELR_sv.py merge_vcf {input} {output}"

rule sv_read_IDlist: # get a list of all the read IDs from the parsed vcf file
    input:
        "intermediate_files/{sample_name}.vcf_filtered.tsv"
    output:
        "{sample_name}.id"
    shell:
        "python3 TELR_assembly.py write_read_IDs {input} {output}"

rule unique_IDlist: # get a list of unique IDs from the readlist
    input:
        "{sample_name}.id"
    output:
        "{sample_name}.id.unique"
    shell:
        "cat {input} | sort | uniq > {output}"

"""
2nd stage: assembly and polish local TE contig
"""

'''2nd stage
Local contig assembly and polishing (wtdbg2/flye + minimap2)
'''

rule filter_readlist: # use seqtk to get the fasta reads from the input reads file
    input:
        "{sample_name}.id.unique"
    output:
        "{sample_name}.subset.fa"
    shell:
        "seqtk subseq {config[fasta_reads]} {input} | seqtk seq -a > {output}"

rule make_contig_file:
    input:
        vcf_parsed = lambda wildcards: f"intermediate_files/{config['sample_name']}.vcf_filtered.tsv",
        reads = lambda wildcards: f"{config['sample_name']}.subset.fa"
    output:
        "sv_reads/{contig}.reads.fa"
    shell:
        "python3 TELR_assembly.py make_contig_file {input.vcf_parsed} {wildcards.contig} {output} {input.reads}"

rule run_assembly:
    input:
        "sv_reads/{contig}.reads.fa"
    output:
        "intermediate_files/contig_assembly/{contig}.initial_cns.fa"
    params:
        asm_dir = "intermediate_files/contig_assembly"
    threads: 1
    shell:
        """
        python3 TELR_assembly.py run_{config[assembler]}_assembly {input} {params.asm_dir} {wildcards.contig} {threads} {config[presets]} {output} || true
        touch {output}
        """

rule run_polishing:
    input:
        reads = "sv_reads/{contig}.reads.fa",
        initial_assembly = "intermediate_files/contig_assembly/{contig}.initial_cns.fa"
    output:
        "intermediate_files/contig_assembly/{contig}.cns.fa"
    params:
        asm_dir = "intermediate_files/contig_assembly"
    threads: 1
    shell:
        """
        python3 TELR_assembly.py run_{config[polisher]}_polishing {input.initial_assembly} {output} {input.reads} {params.asm_dir} {wildcards.contig} {threads} {config[polish_iterations]} {config[presets]} || true
        touch {output}
        """

rule get_parsed_contigs:
    input:
        "intermediate_files/contig_assembly/{contig}.cns.fa"
    output:
        "intermediate_files/contig_assembly/{contig}.cns.ctg1.fa"
    shell:
        """
        python3 TELR_assembly.py parse_assembled_contig {input} {output} || true
        touch {output}
        """

def all_contigs(wildcards):
    vcf_parsed_file = checkpoints.merge_parsed_vcf.get(**wildcards).output[0]
    with open(vcf_parsed_file) as vcf_parsed:
        contig_filenames = []
        for line in vcf_parsed:
            contig_name = "_".join(line.split()[:3])
            contig_filenames.append(f"intermediate_files/contig_assembly/{contig_name}.cns.ctg1.fa")
        return contig_filenames
rule merged_contigs:
    input:
        all_contigs
    output:
        "{sample_name}.contigs.fa"
    params:
        asm_dir = "intermediate_files/contig_assembly"
    shell:
        """
        cat {input} > {output}
        find {params.asm_dir} -type f -empty -delete
        """


"""
3rd stage: annotate TE and predict location in reference genome
"""

'''3rd stage
Contig TE annotation (minimap2 + RepeatMasker)
'''

'''3rd stage
Identify TE insertion breakpoint (minimap2)
'''

"""
4th stage: estimate intra-sample TE allele frequency (TAF)
"""

'''4th stage
Read extraction (samtools)
'''

'''4th stage
Read alignment to TE contig (minimap2)
'''

'''4th stage
Depth-based TAF estimation (SAMtools)
'''