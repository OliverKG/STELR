import os

rule all:
    input: 
        "intermediate_files/reads.vcf_filtered.tsv"
        #"{sample_name}.loci_eval.tsv"

rule bam_input: #if input is given in bam format, convert it to fasta format.
    #todo -- check if this bam format is ACTUALLY aligned.
    input:
        "intermediate_files/input/reads-{sample_name}.bam"
    output:
        "intermediate_files/input/reads-{sample_name}.fasta"
    shell:
        "python3 TELR_alignment.py bam2fasta {input} {output}"

"""
1st stage: identify TE insertion candidate loci
"""

'''1st stage
"Read alignment (NGMLR)"
^(or minimap2)
'''
#only run if reads are supplied in fasta format
rule alignment:
    input:
        'intermediate_files/input/reads-{sample_name}.f{asta_reads}'
    output:
        "intermediate_files/{sample_name}.sam"
    params:
        reads = "intermediate_files/inputs/reads-{sample_name}.f{asta_reads}",
        #{asta_reads}, {asta_ref}, etc: read file extension may be .fna, .fa, .fasta, etc:
        #.f has to be outside of the wildcard so that snakemake knows the file extension must start with f,
        #but wildcard included so that it will accept any variation of a fasta file.
        reference = "intermediate_files/inputs/reference-{sample_name}.f{asta_ref}",
        out = "intermediate_files",
        method = config["aligner"],#minimap2 or ngmlr
        presets = config["presets"]#ont or pacbio
    threads: config["thread"]
    shell:
        "python3 TELR_alignment.py alignment {params.reads} {params.reference} {params.out} {wildcards.sample_name} {threads} {params.method} {params.presets}"

def find_alignment(wildcards):
    bam_input = f"intermediate_files/input/reads-{wildcards.sample_name}.bam"
    if(os.path.is_file(bam_input)): return bam_input
    else: return f"intermediate_files/{wildcards.sample_name}.sam"
rule sort_index_bam:
    input:
        find_alignment#gives name of input file (this depends on whether the user supplied input was in bam format or it was aligned later)
    output:
        "intermediate_files/{sample_name}_sort.bam"
    threads: config["thread"]
    conda:
        config["conda"]
        #samtools
    shell:
        "python3 TELR_alignment.py sort_index_bam {input} {output} {threads}"
    
'''1st stage
SV calling (Sniffles)
'''
rule detect_sv:
    input:
        bam = "intermediate_files/{sample_name}_sort.bam",
        reference = "intermediate_files/input/reference-{sample_name}.f{asta_ref}"
    output:
        "intermediate_files/{sample_name}_{sv_detector}.vcf"
    params:
        out = "intermediate_files",
        sample_name = config["sample_name"],
        thread = config["thread"]
    conda:
        config["conda"]
    shell:
        "python3 TELR_sv.py detect_sv {input.bam} {input.reference} {params.out} {params.sample_name} {params.thread}"

rule parse_vcf:
    input:
        "intermediate_files/{sample_name}_{sv_detector}.vcf"
    output:
        "intermediate_files/{sample_name}.vcf_parsed.tsv.tmp"
    params:
        '"%CHROM\\t%POS\\t%END\\t%SVLEN\\t%RE\\t%AF\\t%ID\\t%ALT\\t%RNAMES\\t%FILTER\\t[ %GT]\\t[ %DR]\\t[ %DV]\n"'
    conda:
        config["conda"]
        #bcftools
    shell:
        'bcftools query -i \'SVTYPE="INS" & ALT!="<INS>"\' -f {params} {input} > {output}'

rule swap_vcf_coordinate:
    input:
        "intermediate_files/{sample_name}.vcf_parsed.tsv.tmp"
    output:
        "intermediate_files/{sample_name}.vcf_parsed.tsv.swap"
    conda:
        config["conda"]
    shell:
        "python3 TELR_sv.py swap_coordinate {input} {output}"

rule rm_vcf_redundancy:
    input:
        "intermediate_files/{sample_name}.vcf_parsed.tsv.swap"
    output:
        "intermediate_files/{sample_name}.vcf_parsed.tsv"
    conda:
        config["conda"]
    shell:
        "python3 TELR_sv.py rm_vcf_redundancy {input} {output}"

rule write_ins_seqs:
    input:
        "intermediate_files/{sample_name}.vcf_parsed.tsv"
    output:
        "intermediate_files/{sample_name_plus}.vcf_ins.fasta"
    params:
        output_file = lambda config: f"intermediate_files/{config["sample_name"].replace("+","plus")}.vcf_ins.fasta"
    conda:
        config["conda"]
    shell:
        "python3 TELR_sv.py write_ins_seqs {input} {params.output_file}"

'''1st stage
Filter for TE insertion candidate (RepeatMasker)
'''
rule sv_repeatmask:
    input:
        ins_seqs = "intermediate_files/{sample_name_plus}.vcf_ins.fasta",
        library = "intermediate_files/input/library-{sample_name}.f{asta_lib}"
    output:
        "intermediate_files/vcf_ins_repeatmask/{ins_seqs}.out.gff"
    params:
        repeatmasker_dir = "intermediate_files/vcf_ins_repeatmask",
        thread = config["thread"]
    conda:
        config["conda"]
    shell:
        "python3 TELR_sv.py repeatmask {params.repeatmasker_dir} {input.ins_seqs} {input.library} {params.thread}"

rule sv_RM_sort:
    input:
        "intermediate_files/vcf_ins_repeatmask/{ins_seqs}.out.gff"
    output:
        "intermediate_files/vcf_ins_repeatmask/{ins_seqs}.out.sort.gff"
    conda:
        config["conda"]
        #bedtools
    shell:
        "bedtools sort -i {input} > {output}"

rule sv_RM_merge:
    input:
        "intermediate_files/vcf_ins_repeatmask/{ins_seqs}.out.sort.gff"
    output:
        "intermediate_files/vcf_ins_repeatmask/{ins_seqs}.out.merge.bed"
    conda:
        config["conda"]
        #bedtools
    shell:
        "bedtools merge -i {input} > {output}"

rule sv_TE_extract:
    input:
        parsed_vcf = "intermediate_files/{sample_name}.vcf_parsed.tsv",
        ins_seqs = "intermediate_files/{sample_name_plus}.vcf_ins.fasta",
        ins_rm_merge = "intermediate_files/vcf_ins_repeatmask/{ins_seqs}.out.merge.bed"
    output:
        ins_filtered = "intermediate_files/{sample_name}.vcf.filtered.tmp.tsv",
        loci_eval = "{sample_name}.loci_eval.tsv"
    conda:
        config["conda"]
    shell:
        "python3 TELR_sv.py te_extract {input.parsed_vcf} {input.ins_seqs} {input.ins_rm_merge} {output.ins_filtered} {output.loci_eval}"

rule seq_merge:
    input:
        "intermediate_files/{sample_name}.vcf.filtered.tmp.tsv"
    output: 
        "intermediate_files/{sample_name}.vcf.merged.tmp.tsv"
    params:
        window = 20
    conda:
        config["conda"]
        #bedtools
    shell:
        'bedtools merge -o collapse -c 2,3,4,5,6,7,8,9,10,11,12,13,14 -delim ";" -d {params.window} -i {input} > {output}'

rule process_merge:
    input:
        "intermediate_files/{sample_name}.vcf.merged.tmp.tsv"
    output:
        "intermediate_files/{sample_name}.vcf_filtered.tsv"
    conda:
        config["conda"]
    shell:
        "python3 TELR_sv.py merge_vcf {input} {output}"

"""
2nd stage: assembly and polish local TE contig
"""

'''2nd stage
Local condig assembly and polishing (wtdbg2/flye + minimap2)
'''

"""
3rd stage: annotate TE and predict location in reference genome
"""

'''3rd stage
Contig TE annotation (minimap2 + RepeatMasker)
'''

'''3rd stage
Identify TE insertion breakpoint (minimap2)
'''

"""
4th stage: estimate intra-sample TE allele frequency (TAF)
"""

'''4th stage
Read extraction (samtools)
'''

'''4th stage
Read alignment to TE contig (minimap2)
'''

'''4th stage
Depth-based TAF estimation (SAMtools)
'''